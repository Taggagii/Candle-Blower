{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f42007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52cd896a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19f09375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path(\"camera_interface/img/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21598754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2978"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(data_dir.glob('*/*.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d7c601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a734cfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2978 files belonging to 2 classes.\n",
      "Using 2383 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47deb34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2978 files belonging to 2 classes.\n",
      "Using 595 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f569a24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da9862c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7282cf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 180, 180, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "723ac932",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8574cdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f32187c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3c1a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16f06b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8abe9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "75/75 [==============================] - 46s 616ms/step - loss: 0.1894 - accuracy: 0.9362 - val_loss: 0.0516 - val_accuracy: 0.9798\n",
      "Epoch 2/3\n",
      "75/75 [==============================] - 51s 677ms/step - loss: 0.0449 - accuracy: 0.9870 - val_loss: 0.0500 - val_accuracy: 0.9815\n",
      "Epoch 3/3\n",
      "75/75 [==============================] - 51s 675ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.0389 - val_accuracy: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa8b9f232b0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d26da72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "881c2281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.261213 , -8.4932   ],\n",
       "       [-6.873396 ,  6.7214584],\n",
       "       [ 6.144649 , -3.5079007]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(tf.reshape(images[0:3], (3, 180, 180, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2dd81005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([180, 180, 3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ddcf2ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 180, 180, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(images[0], (1, 180, 180, 3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a745f4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function reshape in module tensorflow.python.ops.array_ops:\n",
      "\n",
      "reshape(tensor, shape, name=None)\n",
      "    Reshapes a tensor.\n",
      "    \n",
      "    Given `tensor`, this operation returns a new `tf.Tensor` that has the same\n",
      "    values as `tensor` in the same order, except with a new shape given by\n",
      "    `shape`.\n",
      "    \n",
      "    >>> t1 = [[1, 2, 3],\n",
      "    ...       [4, 5, 6]]\n",
      "    >>> print(tf.shape(t1).numpy())\n",
      "    [2 3]\n",
      "    >>> t2 = tf.reshape(t1, [6])\n",
      "    >>> t2\n",
      "    <tf.Tensor: shape=(6,), dtype=int32,\n",
      "      numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>\n",
      "    >>> tf.reshape(t2, [3, 2])\n",
      "    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "      array([[1, 2],\n",
      "             [3, 4],\n",
      "             [5, 6]], dtype=int32)>\n",
      "    \n",
      "    The `tf.reshape` does not change the order of or the total number of elements\n",
      "    in the tensor, and so it can reuse the underlying data buffer. This makes it\n",
      "    a fast operation independent of how big of a tensor it is operating on.\n",
      "    \n",
      "    >>> tf.reshape([1, 2, 3], [2, 2])\n",
      "    Traceback (most recent call last):\n",
      "    ...\n",
      "    InvalidArgumentError: Input to reshape is a tensor with 3 values, but the\n",
      "    requested shape has 4\n",
      "    \n",
      "    To instead reorder the data to rearrange the dimensions of a tensor, see\n",
      "    `tf.transpose`.\n",
      "    \n",
      "    >>> t = [[1, 2, 3],\n",
      "    ...      [4, 5, 6]]\n",
      "    >>> tf.reshape(t, [3, 2]).numpy()\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [5, 6]], dtype=int32)\n",
      "    >>> tf.transpose(t, perm=[1, 0]).numpy()\n",
      "    array([[1, 4],\n",
      "           [2, 5],\n",
      "           [3, 6]], dtype=int32)\n",
      "    \n",
      "    If one component of `shape` is the special value -1, the size of that\n",
      "    dimension is computed so that the total size remains constant.  In particular,\n",
      "    a `shape` of `[-1]` flattens into 1-D.  At most one component of `shape` can\n",
      "    be -1.\n",
      "    \n",
      "    >>> t = [[1, 2, 3],\n",
      "    ...      [4, 5, 6]]\n",
      "    >>> tf.reshape(t, [-1])\n",
      "    <tf.Tensor: shape=(6,), dtype=int32,\n",
      "      numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>\n",
      "    >>> tf.reshape(t, [3, -1])\n",
      "    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "      array([[1, 2],\n",
      "             [3, 4],\n",
      "             [5, 6]], dtype=int32)>\n",
      "    >>> tf.reshape(t, [-1, 2])\n",
      "    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "      array([[1, 2],\n",
      "             [3, 4],\n",
      "             [5, 6]], dtype=int32)>\n",
      "    \n",
      "    `tf.reshape(t, [])` reshapes a tensor `t` with one element to a scalar.\n",
      "    \n",
      "    >>> tf.reshape([7], []).numpy()\n",
      "    7\n",
      "    \n",
      "    More examples:\n",
      "    \n",
      "    >>> t = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "    >>> print(tf.shape(t).numpy())\n",
      "    [9]\n",
      "    >>> tf.reshape(t, [3, 3])\n",
      "    <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "      array([[1, 2, 3],\n",
      "             [4, 5, 6],\n",
      "             [7, 8, 9]], dtype=int32)>\n",
      "    \n",
      "    >>> t = [[[1, 1], [2, 2]],\n",
      "    ...      [[3, 3], [4, 4]]]\n",
      "    >>> print(tf.shape(t).numpy())\n",
      "    [2 2 2]\n",
      "    >>> tf.reshape(t, [2, 4])\n",
      "    <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "      array([[1, 1, 2, 2],\n",
      "             [3, 3, 4, 4]], dtype=int32)>\n",
      "    \n",
      "    >>> t = [[[1, 1, 1],\n",
      "    ...       [2, 2, 2]],\n",
      "    ...      [[3, 3, 3],\n",
      "    ...       [4, 4, 4]],\n",
      "    ...      [[5, 5, 5],\n",
      "    ...       [6, 6, 6]]]\n",
      "    >>> print(tf.shape(t).numpy())\n",
      "    [3 2 3]\n",
      "    >>> # Pass '[-1]' to flatten 't'.\n",
      "    >>> tf.reshape(t, [-1])\n",
      "    <tf.Tensor: shape=(18,), dtype=int32,\n",
      "      numpy=array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6],\n",
      "      dtype=int32)>\n",
      "    >>> # -- Using -1 to infer the shape --\n",
      "    >>> # Here -1 is inferred to be 9:\n",
      "    >>> tf.reshape(t, [2, -1])\n",
      "    <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
      "      array([[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "             [4, 4, 4, 5, 5, 5, 6, 6, 6]], dtype=int32)>\n",
      "    >>> # -1 is inferred to be 2:\n",
      "    >>> tf.reshape(t, [-1, 9])\n",
      "    <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
      "      array([[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "             [4, 4, 4, 5, 5, 5, 6, 6, 6]], dtype=int32)>\n",
      "    >>> # -1 is inferred to be 3:\n",
      "    >>> tf.reshape(t, [ 2, -1, 3])\n",
      "    <tf.Tensor: shape=(2, 3, 3), dtype=int32, numpy=\n",
      "      array([[[1, 1, 1],\n",
      "              [2, 2, 2],\n",
      "              [3, 3, 3]],\n",
      "             [[4, 4, 4],\n",
      "              [5, 5, 5],\n",
      "              [6, 6, 6]]], dtype=int32)>\n",
      "    \n",
      "    Args:\n",
      "      tensor: A `Tensor`.\n",
      "      shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "        Defines the shape of the output tensor.\n",
      "      name: Optional string. A name for the operation.\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `tensor`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0b08784",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4c84e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_3 (Rescaling)      (None, 180, 180, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 178, 178, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 89, 89, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 87, 87, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 43, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 41, 41, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1638528   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,658,178\n",
      "Trainable params: 1,658,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a297fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.261215, -8.493198]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(tf.reshape(images[0], (1, 180, 180, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7420beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
